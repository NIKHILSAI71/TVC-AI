# =============================================================================
# TVC-AI Improved Training Configuration
# Research-backed configuration for stable SAC training
# =============================================================================

defaults:
  - env: curriculum  # Use curriculum learning environment
  - agent: sac_improved  # Use improved SAC configuration
  - training: improved  # Use improved training schedule
  - logging: standard
  - _self_

# =============================================================================
# GLOBAL SETTINGS
# =============================================================================
globals:
  project_name: "TVC-AI-Improved"
  experiment_name: "rocket_tvc_sac_curriculum_v1"
  output_dir: "./outputs/improved/${now:%Y-%m-%d}/${now:%H-%M-%S}"
  seed: 42
  debug: true  # Enable debugging for initial runs
  device: "auto"
  num_workers: 2  # Conservative worker count

# =============================================================================
# WEIGHTS & BIASES CONFIGURATION
# =============================================================================
wandb:
  enabled: true  # ENABLE W&B for better tracking
  project: "tvc-ai-improved"
  entity: null
  tags: ["sac", "rocket", "tvc", "curriculum", "improved"]
  notes: "Improved SAC training with curriculum learning and research-backed hyperparameters"
  mode: "online"

# =============================================================================
# SPECIFIC OVERRIDES FOR IMPROVED TRAINING
# =============================================================================

# Environment-specific overrides
env:
  # Start with very conservative settings
  rocket:
    max_initial_tilt: 0.5  # Very small initial tilt
    thrust_std: 1.0  # Low thrust variation
  
  # Disable challenging features initially
  domain_randomization:
    enabled: false  # Will be enabled by curriculum
  
  sensor_noise:
    enabled: false  # Will be enabled by curriculum

# Agent-specific overrides
agent:
  # Conservative network settings
  architecture:
    hidden_dims: [256, 256]  # Smaller network
    layer_norm: true  # CRITICAL for stability
  
  # Conservative learning settings
  optimization:
    lr_actor: 0.0003  # Conservative learning rate
    grad_clip_norm: 1.0  # Strict gradient clipping
  
  # Exploration settings
  exploration:
    use_sde: true  # Enable gSDE
    n_steps: 3  # Use n-step returns

# Training-specific overrides
training:
  total_steps: 650000  # Extended training for curriculum
  
  # More frequent evaluation during curriculum
  evaluation:
    eval_freq: 15000  # More frequent evaluation
    eval_episodes: 30  # More episodes for stable estimates
  
  # Enable detailed monitoring
  monitoring:
    detailed_episode_logging: true
    log_reward_components: true
    save_episode_videos: true

# =============================================================================
# DEBUGGING AND MONITORING OVERRIDES
# =============================================================================

# Enhanced logging for troubleshooting
logging:
  console_log_interval: 100  # More frequent console logs
  tensorboard:
    enabled: true
    log_histograms: true  # Monitor weight distributions
    log_scalars: true
    log_images: true  # Visualize episodes
  
  # File logging
  file_logging:
    enabled: true
    log_level: "DEBUG"
    save_logs: true

# =============================================================================
# RESEARCH-BACKED HYPERPARAMETER NOTES
# =============================================================================

# NOTES FOR USERS:
# 1. This configuration implements findings from Antonin Raffin's 2024-2025 research
# 2. Key improvements:
#    - gSDE for consistent exploration
#    - Layer normalization for training stability
#    - Curriculum learning with staged difficulty
#    - Conservative hyperparameters to prevent divergence
#    - Proper action space management
# 3. Expected results:
#    - Stage 1 (0-150K): Learn basic stabilization (60%+ success)
#    - Stage 2 (150K-350K): Handle moderate disturbances (50%+ success)
#    - Stage 3 (350K-650K): Master full challenge (40%+ success)
# 4. If training still fails:
#    - Reduce network size further: [128, 128]
#    - Increase curriculum stage durations
#    - Enable more debugging options

# =============================================================================
# HYDRA CONFIGURATION
# =============================================================================
hydra:
  run:
    dir: ${globals.output_dir}
  job:
    name: tvc_ai_improved_training
