# =============================================================================
# Training Configuration - Improved for SAC Stability
# Research-backed training schedule for continuous control
# =============================================================================

# Training duration and scheduling
total_steps: 650000  # Total training steps (covers all curriculum stages)
warmup_steps: 10000  # Extended warmup for exploration

# Evaluation settings
evaluation:
  eval_freq: 20000  # Evaluate every 20K steps
  eval_episodes: 20  # More episodes for stable evaluation
  eval_deterministic: true  # Use deterministic policy for evaluation
  eval_render: false  # No rendering during evaluation
  
  # Final evaluation
  final_eval_episodes: 100  # Comprehensive final evaluation
  final_eval_render: true  # Record final videos

# Model saving and checkpointing
checkpointing:
  checkpoint_freq: 50000  # Save checkpoint every 50K steps
  save_best_model: true  # Save best performing model
  save_final_model: true  # Save final model
  keep_n_checkpoints: 5  # Keep last 5 checkpoints
  
  # Model export
  export_onnx: true  # Export to ONNX format
  export_tflite: true  # Export to TensorFlow Lite

# Early stopping criteria
early_stopping:
  enabled: true
  patience: 10  # Stop if no improvement for 10 evaluations
  min_improvement: 10.0  # Minimum reward improvement
  
  # Curriculum-aware early stopping
  curriculum_aware: true  # Consider curriculum stage in early stopping

# Progress monitoring and diagnostics
monitoring:
  # Training diagnostics
  log_training_metrics: true
  log_network_stats: true  # Log weight statistics
  log_action_distribution: true  # Monitor action usage
  
  # Episode analysis
  detailed_episode_logging: true
  log_trajectory_data: true  # Save trajectory data for analysis
  success_criteria_logging: true
  
  # Visualization
  plot_training_curves: true
  save_episode_videos: true  # Save videos of episodes
  video_frequency: 10000  # Save video every 10K steps

# Performance optimization
performance:
  # Parallel environments
  num_envs: 1  # Start with single environment for debugging
  num_eval_envs: 4  # Multiple evaluation environments
  
  # Data loading
  num_workers: 2  # Data loading workers
  prefetch_factor: 2  # Prefetch batches
  
  # Memory management
  buffer_optimization: true  # Optimize replay buffer memory usage
  gradient_accumulation: false  # Disable gradient accumulation initially

# Debugging and visualization
debugging:
  # Detailed logging for troubleshooting
  log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  verbose_training: true  # Detailed training logs
  
  # Action space analysis
  monitor_action_bounds: true  # Track action space usage
  log_reward_components: true  # Log individual reward components
  
  # Episode debugging
  save_failed_episodes: true  # Save data from failed episodes
  analyze_termination_causes: true  # Log why episodes terminate
  
  # Network debugging
  monitor_gradient_norms: true  # Track gradient magnitudes
  log_entropy_evolution: true  # Monitor exploration levels
  
# Curriculum learning integration
curriculum_integration:
  # Automatic stage progression
  auto_stage_progression: true
  stage_evaluation_episodes: 50  # Episodes to evaluate stage completion
  
  # Stage transition smoothing
  smooth_transitions: true  # Gradually transition between stages
  transition_steps: 10000  # Steps to transition between stages
  
  # Adaptive curriculum
  adaptive_difficulty: true  # Adjust difficulty based on performance
  difficulty_adjustment_rate: 0.1  # Rate of difficulty adjustment

# Hyperparameter scheduling
scheduling:
  # Learning rate scheduling
  lr_scheduling:
    enabled: false  # Disabled initially for stability
    schedule_type: "cosine"  # linear, cosine, exponential
    warmup_fraction: 0.1
  
  # Exploration scheduling
  exploration_scheduling:
    enabled: true
    initial_exploration: 0.3  # High initial exploration
    final_exploration: 0.05  # Low final exploration
    decay_type: "exponential"  # linear, exponential
  
  # Batch size scheduling
  batch_size_scheduling:
    enabled: false  # Keep constant initially
    initial_batch_size: 128
    final_batch_size: 512
    growth_rate: 1.1

# Experimental features
experimental:
  # Advanced techniques
  priority_experience_replay: false  # Disable initially
  hindsight_experience_replay: false  # Disable initially
  distributional_critic: false  # Disable initially
  
  # Regularization techniques
  spectral_normalization: false  # Disable initially
  batch_normalization: false  # Use layer norm instead
  dropout_scheduling: false  # Keep constant dropout
  
  # Multi-objective learning
  multi_objective_learning: false  # Single objective initially
  reward_shaping: true  # Enable reward shaping
  curriculum_reward_scaling: true  # Scale rewards by curriculum stage

# Success metrics and reporting
success_metrics:
  # Primary metrics
  success_rate_threshold: 0.7  # Target success rate
  average_reward_threshold: 500.0  # Target average reward
  
  # Secondary metrics
  episode_length_target: 800  # Target episode length
  control_smoothness_target: 0.1  # Target control smoothness
  
  # Stability metrics
  reward_variance_threshold: 100.0  # Maximum acceptable reward variance
  success_rate_variance_threshold: 0.1  # Maximum success rate variance

# Model deployment preparation
deployment:
  # Model optimization
  quantization:
    enabled: true
    quantization_type: "dynamic"  # dynamic, static, qat
    target_platform: "tflite"  # tflite, onnx, tensorrt
  
  # Model validation
  deployment_testing:
    enabled: true
    test_episodes: 100  # Test episodes for deployment validation
    performance_threshold: 0.9  # Minimum performance vs training
  
  # Export settings
  export_format: ["pytorch", "onnx", "tflite"]  # Multiple formats
  include_preprocessing: true  # Include preprocessing in exported model
  include_postprocessing: true  # Include postprocessing in exported model
