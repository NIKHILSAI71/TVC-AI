# =============================================================================
# Environment Configuration - Curriculum Learning
# Staged difficulty progression for stable SAC training
# =============================================================================

# Environment type and basic settings
env_id: "RocketTVC-v1"
max_episode_steps: 1000  # Shorter episodes initially
render_mode: null
physics_timestep: 0.004167
control_frequency: 50

# Rocket physical properties - Conservative starting parameters
rocket:
  # Basic physical parameters
  mass: 2.0  # Slightly heavier for stability
  radius: 0.05
  length: 0.8
  inertia_ratio: 8.0  # Reduced for easier control
  
  # Motor specifications - Predictable thrust
  thrust_mean: 45.0  # Slightly lower thrust
  thrust_std: 2.0  # Much lower variation initially
  burn_time: 4.0  # Longer burn time
  
  # TVC system parameters - Conservative limits
  max_gimbal_angle: 15.0  # Reduced from 25.0 degrees
  gimbal_response_time: 0.03  # Faster response
  max_gimbal_rate: 80.0  # Slightly slower rate
  
  # Initial conditions - EASY START
  initial_altitude: 2.0  # Higher starting altitude
  target_altitude: 3.0  # Closer target
  max_initial_tilt: 0.5  # Very small initial tilt
  max_initial_angular_vel: 0.1  # Very small initial angular velocity

# Curriculum Learning - CRITICAL ADDITION
curriculum:
  enabled: true  # ENABLE CURRICULUM LEARNING
  
  # Stage 1: Basic Stabilization (Learn to not fall over)
  stage_1:
    name: "basic_stabilization"
    duration_steps: 150000  # 150K steps to master basics
    conditions:
      max_initial_tilt: 0.5  # degrees - very easy
      max_initial_angular_vel: 0.1  # rad/s - very low
      domain_randomization: false  # NO randomization
      sensor_noise: false  # NO noise
      max_gimbal_angle: 10.0  # Limited control authority
      wind_enabled: false  # No wind disturbances
    success_criteria:
      min_success_rate: 0.6  # 60% success rate to advance
      min_avg_reward: 100.0  # Positive average reward
      evaluation_episodes: 50  # Test over 50 episodes
  
  # Stage 2: Moderate Disturbances
  stage_2:
    name: "moderate_disturbances"
    duration_steps: 200000  # 200K steps
    conditions:
      max_initial_tilt: 2.0  # degrees - moderate
      max_initial_angular_vel: 0.3  # rad/s
      domain_randomization: true
      randomization_strength: 0.3  # 30% variation
      sensor_noise: false  # Still no sensor noise
      max_gimbal_angle: 15.0  # More control authority
      wind_enabled: false
    success_criteria:
      min_success_rate: 0.5
      min_avg_reward: 200.0
      evaluation_episodes: 50
  
  # Stage 3: Full Challenge
  stage_3:
    name: "full_challenge"
    duration_steps: 300000  # 300K steps
    conditions:
      max_initial_tilt: 5.0  # degrees - challenging
      max_initial_angular_vel: 0.5  # rad/s
      domain_randomization: true
      randomization_strength: 1.0  # Full variation
      sensor_noise: true  # Add sensor noise
      max_gimbal_angle: 25.0  # Full control authority
      wind_enabled: true
    success_criteria:
      min_success_rate: 0.4
      min_avg_reward: 300.0
      evaluation_episodes: 100

# Domain randomization - STAGED INTRODUCTION
domain_randomization:
  enabled: false  # Will be enabled by curriculum
  
  # Mass and inertia randomization
  mass_variation: 0.15  # Reduced from 0.2
  cg_offset_max: 0.03  # Reduced from 0.05
  inertia_variation: 0.1  # Reduced from 0.15
  
  # Thrust and motor randomization
  thrust_variation: 0.2  # Reduced from 0.3
  burn_time_variation: 0.05  # Reduced from 0.1
  
  # Environmental conditions
  wind_force_max: 1.5  # Reduced from 2.0
  wind_direction_variation: 30  # degrees
  gravity_variation: 0.02  # Â±2% gravity variation

# Sensor noise - DELAYED INTRODUCTION
sensor_noise:
  enabled: false  # Will be enabled by curriculum
  
  # IMU noise
  gyro_noise_std: 0.05  # Reduced from 0.1
  accel_noise_std: 0.1
  quaternion_noise_std: 0.005  # Reduced from 0.01
  
  # Actuator noise
  gimbal_noise_std: 0.5  # degrees
  thrust_noise_std: 1.0  # N

# Simplified reward function for initial learning
reward:
  # Primary objectives - SIMPLIFIED
  attitude_stability_weight: 10.0  # Reduced from 15.0
  altitude_control_weight: 5.0
  angular_velocity_weight: 0.1  # Reduced penalty
  
  # Control efficiency
  control_effort_weight: 0.001  # Much reduced
  control_smoothness_weight: 0.001
  
  # Success bonuses
  stability_bonus: 5.0  # Increased bonus
  target_reached_bonus: 20.0  # Big bonus for success
  
  # Termination penalties - REDUCED
  crash_penalty: -20.0  # Reduced from -50.0
  tilt_penalty: -15.0  # Reduced from -30.0
  timeout_penalty: -5.0  # Small timeout penalty
  
  # Success criteria
  success_tilt_threshold: 15.0  # degrees - more lenient
  success_altitude_threshold: 1.0  # meters
  stability_time_required: 1.0  # seconds

# Termination conditions - MORE LENIENT
termination:
  max_tilt_angle: 60.0  # degrees - increased from 45.0
  min_altitude: -0.5  # Allow slight ground contact
  max_altitude: 15.0
  max_horizontal_distance: 30.0  # Reduced from 50.0
  max_angular_velocity: 15.0  # rad/s - increased from 10.0

# Action space bounds - WILL BE SET BY CURRICULUM
action_bounds:
  # These will be set automatically based on successful trajectories
  adaptive_bounds: true
  initial_bounds: [-1.0, 1.0]  # Start with full range
  percentile_bounds: [2.5, 97.5]  # Use 95% of successful actions
